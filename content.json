[{"title":"zookeeper的副本","date":"2021-02-01T06:07:48.713Z","path":"2021/02/01/zookeeper的副本/","text":"https://zhuanlan.zhihu.com/p/65366906 https://zhuanlan.zhihu.com/p/142000763","slug":"zookeeper的副本","updated":"2021-02-01T06:27:28.606Z","comments":true,"categories":[],"tags":[]},{"title":"G1收集器的副本","date":"2021-01-31T06:14:02.964Z","path":"2021/01/31/G1收集器的副本/","text":"目标 参考 参考G1收集器适用于多核,内存使用较多的应用,以低停顿为首要目标,同时兼顾较高吞吐量,简化配置.通常适用于这些应用: 堆空间超过10GB,并且通常超过50%空间被存活对象占据 堆中存在大量碎片 要求垃圾回收停顿小于几百毫秒 对象分配和提升的比率变化大 重要概念分区(Region)G1将内存划分为多个大小相等的独立区域(Region 大小范围为1M-32M),每块region都会被打唯一的分代标志(eden,survivor,old),仍保留了分代思想,保留了新生代和老年代,但他们不是物理隔离的,而是一部分Region的集合,且不需要Region连续,如下图所示:新生代包含Eden区(红色)和survivor区(红S).蓝色为老年代,大对象被直接分配到老年代中H区, H区由多个连续的Region组成. 每个分区都可能是年轻代也可能是老年代，但是在同一时刻只能属于某个代。 年轻代、幸存区、老年代这些概念还存在，成为逻辑上的概念，这样方便复用之前分代框架的逻辑。在物理上不需要连续，则带来了额外的好处——有的分区内垃圾对象特别多，有的分区内垃圾对象很少，G1会优先回收垃圾对象特别多的分区，这样可以花费较少的时间来回收这些分区的垃圾，这也就是G1名字的由来，即首先收集垃圾最多的分区。 对于新生代来说，并不是使用了这种算法，依然是新生代满了一起进行回收，整个新生代中的对象，要么被回收、要么晋升，至于新生代也采取分区机制的原因，则是因为这样跟老年代的策略统一，方便调整代的大小。 G1还是一种带压缩的收集器，在回收老年代的分区时，是将存活的对象从一个分区拷贝到另一个可用分区，这个拷贝的过程就实现了局部的压缩。每个分区的大小从1M到32M不等，但是都是2的冥次方。 垃圾回收周期Young-only phase此阶段包括新生代垃圾回收(Yong GC)和并发标记(Concurrent Marking Cycle) 在普通的新生代垃圾回收过程中可能会有对象晋升到老年代中,经过多次Young GC后,老年代逐渐被填充,当达到IHOP阈值-XX:InitiatingHeapOccupancyPercent(老年代占整堆比，默认45%)时，便会触发并发标记 收集集合（CSet)一组可被回收的分区的集合。在CSet中存活的数据会在GC过程中被移动到另一个可用分区，CSet中的分区可以来自Eden空间、survivor空间、或者老年代。CSet会占用不到整个堆空间的1%大小。 已记忆集合（RSet）RSet记录了其他Region中的对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）。RSet的价值在于使得垃圾收集器不需要扫描整个堆找到谁引用了当前分区中的对象，只需要扫描RSet即可。 参数参考开启 12345678910# 开启G1-XX:+UseG1GC # 最大GC停顿时间,JVM尽量做到小于这个值-XX:MaxGCPauseMillis=time # 堆被占用多少开始出发GC,默认45%-XX:InitiatingHeapOccupancyPercent=percent # G1为分配担保预留的空间比例, 默认10% 老年代会预留10%的空间来给新生代的对象晋升-XX:G1ReservePercent=percent # Region区域大小 值为2的幂 范围1-32MB 用于根据最小的java堆划分大约2048个区域-XX:G1HeapRegionSize=size 堆大小 12345678## 初始堆大小-XX:InitialHeapSize ## 最大堆-XX:MaxHeapSize## 空闲堆空间的最小百分比,如果当前堆使用空闲空间小于此值,就会在每次垃圾回收后进行扩容 -XX:MinHeapFreeRatio## 空闲堆空间的最大百分比,如果当前堆使用空闲空间大于此值,就会在每次垃圾回收后进行缩容 -XX:MaxHeapFreeRatio 为了满足停顿时间目标,每次Young GC后G1收集器会尝试调整新生代的大小 1234## 新生代比例-XX:G1NewSizePercent## 新生代最大比例-XX:G1MaxNewSizePercent MixGC 123456# 在Space-Reclamation Phase 需要执行mix GC的次数 默认是8-XX:G1MixedGCCountTarget# 如果一个Region的存活对象的空间占比低于此值，则会被纳入Cset-XX:G1MixedGCLiveThresholdPercent# 设置垃圾空间占比来决定Space-Reclamation Phase是否执行mixGC-XX:G1HeapWastePercent 12 收集过程 参考收集策略:G1追踪每个Region中垃圾堆积的价值大小(回收空间大小以及所需时间的经验值),在后台维护一个优先列表,跟据允许的回收价值最大的Region 当Eden空间被占满之后，就会触发YGC。在G1中YGC依然采用复制存活对象到survivor空间的方式，当对象的存活年龄满足晋升条件时，把对象提升到old generation regions(老年代)。G1控制YGC开销的手段是动态改变young region的个数，YGC的过程中依然会STW(stop the world 应用停顿)，并采用多线程并发复制对象，减少GC停顿时间。 G1保留了YGC并加上了一种全新的MIXGC用于收集老年代。整体采用标记整理算法,局部采用复制算法","slug":"G1收集器的副本","updated":"2021-02-03T12:08:08.662Z","comments":true,"categories":[],"tags":[]},{"title":"InnoDB中的锁的副本","date":"2021-01-28T10:08:41.502Z","path":"2021/01/28/InnoDB中的锁的副本/","text":"分类共享锁和排他锁(Shared and Exclusive Locks)InnoDB中实现了数据行级别的共享锁(S)和排他锁(X). 一个事务持有数据行的共享锁时就有权利读取这些数据行. 一个事务持有数据行的排他锁时就可以对这些数据行执行update和delete操作. 共享锁之间相互兼容,共享锁和排他锁以及排他锁和排他锁之间不兼容. 锁之间的兼容性指的是在一个事务持有某数据行的一种锁时,另一个事务试图在这个数据行添加另一种锁时是否会被阻塞. 意向锁(Intention Locks)意向锁为表级别的锁,意向锁分为意向共享锁(IS)和意向排他锁(IX). 一个事务在请求一个表某些数据行的共享锁(S)之前必须先获取这个表的意向共享锁(IS). 一个事务在请求一个表某些数据行的排他锁 (X)之前必须先获取这个表的意向共享锁(IX). 意向锁的主要作用是一个表是否存在数据行被某个事务添加共享锁或者排他锁. 意向锁之间相互兼容 记录锁(Record Locks)记录锁是施加在索引(聚族索引和辅助索引)上的 间隙锁(Gap Locks)间隙锁是封锁索引记录中的间隔，或者第一条索引记录之前的范围，又或者最后一条索引记录之后的范围。 使用唯一索引来搜索并给某一行记录加锁的语句,不会产生间隙锁. 在RR事务隔离级别上并且在下面情况中才可能产生间隙锁: 使用普通索引锁定 使用多列唯一索引 使用唯一索引锁定多行记录(使用唯一索引的范围查找) 间隙锁之间是没有冲突的,不同事务可以在相同的间隙上设置间隙锁,间隙锁的唯一目的就是防止其他事物在间隙上添加数据,防止幻读. Next-Key Locks临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。 临键锁的主要目的，也是为了避免幻读(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。 插入意向锁(Insert Intention Locks)插入意向锁是在insert操作前设置的一种间隙锁(gap lock) 插入意向锁主要作用是给出一种提示:如果多个事务在向相同间隙中插入数据,如果插入的数据没有冲突就不用相互阻塞. 自增锁(AUTO-INC Locks)自增锁是表级别的锁,对于每个含有自增长的表都会有一个自增长计数器,插入操作会根据自增长计数器值+1赋予自增长列, 为了提高插入操作的性能,自增锁不是在事务提交后才释放,而是而是完成对自增长值插入的SQL语句后就释放.为了进一步提高插入操作性能,InnoDB提供了一种轻量级互斥量自增长实现机制,通过对内存中的计数器进行累加操作. 死锁锁信息查询12345show engine innodb statusselect * from information_schema.innodb_trx;select * from information_schema.INNODB_LOCKS;SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;show status like 'innodb_row_lock%'; InnoDB Standard Monitor","slug":"InnoDB中的锁的副本","updated":"2021-01-29T07:44:04.855Z","comments":true,"categories":[],"tags":[]},{"title":"ParNew-CMS-Serial的副本","date":"2021-01-25T07:39:11.412Z","path":"2021/01/25/ParNew-CMS-Serial的副本/","text":"ParNew+CMS+SerialOld新生代采用ParNew收集器 老年代采用CMS+SerialOld配合使用. 常用参数内存配比123456789101112131415## 用来设置堆初始内存大小 需要时1024K的整倍数,并且大于1M 默认物理内存的1/64-Xmssize ## 用来设置新生代大小, 默认整个堆的3/8 ## 如果设置小会导致频繁minor gc如果设置过大会导致只有full gc时才会回收新生代增加回收时间, 一般 设置为堆大小的1/4到1/2之间-Xmnsize## 用来设置堆大小的最大值 需要时1024K的整倍数,并且大于1M 默认物理内存的1/4-Xmxsize ## 新生代和老年代空间比例, 默认是2 老年代:2/3 新生代1/3-XX:NewRatio=ratio ## 设置新生代中Eden区与Survivor区的比值,默认值为8-XX:SurvivorRatio=ratio ParNew 配置参数123456789## 新生代采用ParNew收集器 -XX:+UseParNewGC ## 设置直接进入老年代对象大小阈值 -XX:PretenureSizeThreshold ## 对象能经历多少次Minor GC才晋升到老生代，## 对于 the parallel (throughput) collector默认值是15,对于CMS collector默认值是6.-XX:MaxTenuringThreshold=threshold CMS 配置参数123456789101112131415## 使用CMS收集器,新生代默认采用ParNew收集器-XX:+UseConcMarkSweepGC ## 设置老年代被使用超过多大比例时出发垃圾回收, 如果值为-1时, 就使用-XX:CMSTriggerRatio,默认值为80%-XX:CMSInitiatingOccupancyFraction ## 采用标记-清除算法会产生空间碎片,可能导致无法提供足够空间来存储对像,提前出发FullGC,## 通过下面参数控制在fullGC时进行内存整理-XX:+UseCMS-CompactAtFullCollection ## 或者通过下面参数指定经过多少次垃圾收集就整理一下内存-XX:CMSFullGCsBefore-Compaction## 在CMS重新标记阶段之前的清除（YGC）尝试-XX:CMSScavengeBeforeRemark 垃圾收集步骤老年代参考触发时机根据GC的触发机制分为：周期性Old GC（被动）和主动Old GC 周期性Old GC，执行的逻辑也叫Background Collect，对老年代进行回收，在GC日志中比较常见，由后台线程ConcurrentMarkSweepThread循环判断（默认2s）是否需要触发。 触发条件如果没有设置-XX:+UseCMSInitiatingOccupancyOnly，虚拟机会根据收集的数据决定是否触发(建议线上环境带上这个参数，不然会加大问题排查的难度) 老年代使用率达到阈值 CMSInitiatingOccupancyFraction 新生代的晋升担保失败 收集步骤 初始标记InitialMarking（初始化标记，整个过程STW）该阶段单线程执行，主要分分为两步： 标记GC Roots直接关联的老年代对象； 遍历新生代对象，标记可达的老年代对象； 并发标记该阶段GC线程和应用线程并发执行，遍历InitialMarking阶段标记出来的存活对象，然后继续递归标记这些对象可达的对象。因为该阶段并发执行的，在运行期间可能发生新生代的对象晋升到老年代、或者是直接在老年代分配对象、或者更新老年代对象的引用关系等等，对于这些对象，都是需要进行重新标记的，否则有些对象就会被遗漏，发生漏标的情况。为了提高重新标记的效率，该阶段会把上述对象所在的Card标识为Dirty，后续只需扫描这些Dirty Card的对象，避免扫描整个老年代。 预清理通过参数CMSPrecleaningEnabled选择关闭该阶段，默认启用，主要做两件事情： 处理新生代已经发现的引用，比如在并发阶段，在Eden区中分配了一个A对象，A对象引用了一个老年代对象B（这个B之前没有被标记），在这个阶段就会标记对象B为活跃对象。 在并发标记阶段，如果老年代中有对象内部引用发生变化，会把所在的Card标记为Dirty（其实这里并非使用CardTable，而是一个类似的数据结构，叫ModUnionTalble），通过扫描这些Table，重新标记那些在并发标记阶段引用被更新的对象（晋升到老年代的对象、原本就在老年代的对象） 可中断的预清理该阶段发生的前提是，新生代Eden区的内存使用量大于参数CMSScheduleRemarkEdenSizeThreshold 默认是2M，如果新生代的对象太少，就没有必要执行该阶段，直接执行重新标记阶段。 为什么需要这个阶段，存在的价值是什么？因为CMS GC的终极目标是降低垃圾回收时的暂停时间，所以在该阶段要尽最大的努力去处理那些在并发阶段被应用线程更新的老年代对象，这样在暂停的重新标记阶段就可以少处理一些，暂停时间也会相应的降低。在该阶段，主要循环的做两件事： 处理 From 和 To 区的对象，标记可达的老年代对象 和上一个阶段一样，扫描处理Dirty Card中的对象 当然了，这个逻辑不会一直循环下去，打断这个循环的条件有三个： 可以设置最多循环的次数 CMSMaxAbortablePrecleanLoops，默认是0，意思没有循环次数的限制。 如果执行这个逻辑的时间达到了阈值CMSMaxAbortablePrecleanTime，默认是5s，会退出循环。 如果新生代Eden区的内存使用率达到了阈值CMSScheduleRemarkEdenPenetration，默认50%，会退出循环。（这个条件能够成立的前提是，在进行Precleaning时，Eden区的使用率小于十分之一） 如果在循环退出之前，发生了一次YGC，对于后面的Remark阶段来说，大大减轻了扫描年轻代的负担，但是发生YGC并非人为控制，所以只能祈祷这5s内可以来一次YGC 并发最终标记该阶段并发执行，在之前的并行阶段（GC线程和应用线程同时执行，好比你妈在打扫房间，你还在扔纸屑），可能产生新的引用关系如下： 老年代的新对象被GC Roots引用 老年代的未标记对象被新生代对象引用 老年代已标记的对象增加新引用指向老年代其它对象 新生代对象指向老年代引用被删除 也许还有其它情况.. 上述对象中可能有一些已经在Precleaning阶段和AbortablePreclean阶段被处理过，但总存在没来得及处理的，所以还有进行如下的处理： 遍历新生代对象，重新标记 根据GC Roots，重新标记 遍历老年代的Dirty Card，重新标记，这里的Dirty Card大部分已经在clean阶段处理过 在第一步骤中，需要遍历新生代的全部对象，如果新生代的使用率很高，需要遍历处理的对象也很多，这对于这个阶段的总耗时来说，是个灾难（因为可能大量的对象是暂时存活的，而且这些对象也可能引用大量的老年代对象，造成很多应该回收的老年代对象而没有被回收，遍历递归的次数也增加不少），如果在AbortablePreclean阶段中能够恰好的发生一次YGC，这样就可以避免扫描无效的对象。如果在AbortablePreclean阶段没来得及执行一次YGC，怎么办？CMS算法中提供了一个参数：CMSScavengeBeforeRemark，默认并没有开启，如果开启该参数，在执行该阶段之前，会强制触发一次YGC，可以减少新生代对象的遍历时间，回收的也更彻底一点。不过，这种参数有利有弊，利是降低了Remark阶段的停顿时间，弊的是在新生代对象很少的情况 GC 日志young gc当Eden区内存不够的时候就会触发MinorGC，对新生代区进行一次垃圾回收,采用复制算法进行垃圾收集,并且停止用户线程。 12021-01-25T15:07:08.088+0800: 347639.216: [GC (Allocation Failure) 2021-01-25T15:07:08.089+0800: 347639.217: [ParNew: 634227K-&gt;4937K(707840K), 0.0179037 secs] 1686038K-&gt;1056823K(2018560K), 0.0192075 secs] [Times: user&#x3D;0.20 sys&#x3D;0.04, real&#x3D;0.02 secs] 初始标记12021-01-25T14:51:04.080+0800: 346675.208: [GC (CMS Initial Mark) [1 CMS-initial-mark: 1051619K(1310720K)] 1288072K(2018560K), 0.0312074 secs] [Times: user=0.35 sys=0.10, real=0.03 secs] 并发标记122021-01-25T14:51:04.112+0800: 346675.241: [CMS-concurrent-mark-start]2021-01-25T14:51:04.338+0800: 346675.466: [CMS-concurrent-mark: 0.225&#x2F;0.225 secs] [Times: user&#x3D;1.58 sys&#x3D;0.28, real&#x3D;0.23 secs] 并发预清理122021-01-25T14:51:04.338+0800: 346675.466: [CMS-concurrent-preclean-start]2021-01-25T14:51:04.368+0800: 346675.496: [CMS-concurrent-preclean: 0.028&#x2F;0.030 secs] [Times: user&#x3D;0.07 sys&#x3D;0.00, real&#x3D;0.03 secs] 可中断预清理122021-01-25T14:51:04.368+0800: 346675.496: [CMS-concurrent-abortable-preclean-start] CMS: abort preclean due to time 2021-01-25T14:51:09.386+0800: 346680.515: [CMS-concurrent-abortable-preclean: 4.968&#x2F;5.018 secs] [Times: user&#x3D;13.98 sys&#x3D;0.79, real&#x3D;5.02 secs] 最终标记12021-01-25T14:51:09.395+0800: 346680.523: [GC (CMS Final Remark) [YG occupancy: 240878 K (707840 K)]2021-01-25T14:51:09.395+0800: 346680.523: [GC (CMS Final Remark) 2021-01-25T14:51:09.395+0800: 346680.524: [ParNew: 240878K-&gt;5656K(707840K), 0.0165454 secs] 1292634K-&gt;1057459K(2018560K), 0.0173222 secs] [Times: user&#x3D;0.25 sys&#x3D;0.04, real&#x3D;0.01 secs] 在程序暂停时重新进行扫描(Rescan),以完成存活对象的标记 12021-01-25T14:51:09.413+0800: 346680.541: [Rescan (parallel) , 0.0118097 secs]2021-01-25T14:51:09.425+0800: 346680.553: [weak refs processing, 0.0003596 secs]2021-01-25T14:51:09.425+0800: 346680.553: [class unloading, 0.2218820 secs]2021-01-25T14:51:09.647+0800: 346680.775: [scrub symbol table, 0.0642786 secs]2021-01-25T14:51:09.711+0800: 346680.839: [scrub string table, 0.0065846 secs][1 CMS-remark: 1051802K(1310720K)] 1057459K(2018560K), 0.3230712 secs] [Times: user&#x3D;0.67 sys&#x3D;0.19, real&#x3D;0.32 secs] 并发清除122021-01-25T14:51:09.719+0800: 346680.847: [CMS-concurrent-sweep-start]2021-01-25T14:51:09.947+0800: 346681.076: [CMS-concurrent-sweep: 0.228&#x2F;0.228 secs] [Times: user&#x3D;0.63 sys&#x3D;0.14, real&#x3D;0.23 secs]","slug":"ParNew-CMS-Serial的副本","updated":"2021-02-03T12:07:45.420Z","comments":true,"categories":[],"tags":[]},{"title":"Mysql索引的副本","date":"2021-01-23T08:49:32.818Z","path":"2021/01/23/Mysql索引的副本/","text":"mysql 索引分类1、从存储结构上来划分：BTree索引（B-Tree或B+Tree索引），Hash索引，full-index全文索引，R-Tree索引。这里所描述的是索引存储时保存的形式， 2、从应用层次来分：普通索引，唯一索引，复合索引 3、根据中数据的物理顺序与键值的逻辑（索引）顺序关系：聚集索引，非聚集索引 参考 数据结构B树B树是一种多路搜索树，搜索时从根节点开始，对节点内的有序关键字进行二分查找，如果命中则结束搜索，否则根据搜索大小结果进入左右子节点重复搜索，直到找到搜索结果。 特点： 关键字分布在B树所有节点。 关键字不会重复出现在多个节点。 搜索可能在非叶子节点就结束 B+树B+树实际上是一种特殊的B树，和B树感官最明显的一个不同点在于B+树关键字只会出现在叶子结点中，并且关键字在链表中是有序的，也就是B+树的搜索最后只会在叶子结点中命中结果，那非叶子结点在B+树充当什么角色呢？非叶子节点在B+树中相当于是叶子结点的索引，而叶子结点是存储关键字数据的数据层。既然Mysql索引采用B+树的数据结构，那么相比于B树，B+树做索引的优势在哪里呢： 磁盘读写代价更低。 查询效率更稳定。 遍历元素效率高。 InnoDB索引实现 参考 参考InnoDB中的索引采用B+树的结构实现. 支持关键字, 关键字范围,关键字前缀查询. 聚集索引聚集索引是指数据库表行中数据的物理顺序与键值的逻辑（索引）顺序相同。一个表只能有一个聚集索引，因为一个表的物理顺序只有一种情况，所以，对应的聚集索引只能有一个。如果某索引不是聚集索引，则表中的行物理顺序与索引顺序不匹配，与非聚集索引相比，聚集索引有着更快的检索速度。如下图，叶节点中直接包含了具体数据 非聚集索引与聚集索引不同，非聚集索引的逻辑顺序与磁盘上行的物理存储顺序不同。磁盘上的数据可以随意分布，而通过非聚集索引，可以在逻辑上为数据排序。如下图，叶节点没有包含具体的数据，而是包含了一个指向具体数据的指针。 在InnoDB中，通过主键索引，可以直接获取到具体的数据；而通过辅助索引，在叶节点获取到的是数据的主键，然后再通过主键索引最终获取到数据。 联合索引建立一个基于多个字段的索引。假设某张表中有a，b，c，d四个字段。现在在a，b，c上建立索引(a,b,c)（注意: a,b,c顺序不同建立的是不同的索引）。则索引首先会按a字段排序；在a字段相同的情况下按照b字段排序；在a，b字段相同的情况下按照c字段排序，以此类推。。。 最左前缀匹配原则当建立联合索引时，该索引的所有最左前缀匹配可以用于优化查找。以上面建立的(a,b,c)索引为例，其所有最左前缀匹配为(a),(a,b),(a,b,c)。即涉及到(a),(a,b),(a,b,c)的查找都可以利用索引(a,b,c)，但涉及(a,c)的查找无法利用索引(a,b,c)，因为(a,c)不满足最左前缀匹配原则。 前缀索引前缀索引就是针对字段的“前特定个字符”建立索引，而非对整个字段的值建立索引。显然，因为没有对完整的字段值建立索引，所以这样建立的索引更小，查询更快。MySQL的前缀索引能有效减小索引文件的大小，提高索引的速度。但是前缀索引也有它的坏处：MySQL 不能在 ORDER BY 或 GROUP BY 中使用前缀索引，也不能把它们用作覆盖索引(Covering Index)。可以通过下面的预发建立前缀索引： 1ALTER TABLE table_name ADD KEY(column_name(prefix_length)); 覆盖索引覆盖索引（covering index）指一个查询语句的执行只需要从辅助索引中就可以得到查询记录，而不需要查询聚集索引中的记录。也可以称之为实现了索引覆盖。辅助索引不包含一整行的记录，因此可以大大减少IO操作。覆盖索引是mysql dba常用的一种SQL优化手段。 索引失效基于B+索引中, 每个非叶子结点存放的索引字段的值都是有序的,在查找过程中,在每个非叶子结点通过二分查找的方式来定位数据范围. 在一个查询中如果想只用索引进行查找,必须满足使用的索引能够在一个非叶子结点在查询过程中能够通过二分查找来过滤数据. 以%开头的like查询无法使用 数据类型出现隐式转换 在使用复合索引时不满足最左原则 用or分割的条件,如果一边没有使用索引,就不会使用索引.","slug":"Mysql索引的副本","updated":"2021-01-23T10:11:08.342Z","comments":true,"categories":[],"tags":[]},{"title":"锁的内存语义的副本","date":"2021-01-23T08:40:57.093Z","path":"2021/01/23/锁的内存语义的副本/","text":"Synchronized 参考 锁的内存语义synchronized的底层是使用操作系统的mutex lock实现的。 内存可见性：同步快的可见性是由“如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值”、“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store和write操作）”这两条规则获得的。 操作原子性：持有同一个锁的两个同步块只能串行地进入 锁的内存语义： 当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中 当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量 锁释放和锁获取的内存语义： 线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A对共享变量所做修改的）消息。 线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改的）消息。 线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发送消息 Java对象头在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化，以32位的JDK为例： 锁优化参考","slug":"锁的内存语义的副本","updated":"2021-02-03T10:44:36.873Z","comments":true,"categories":[],"tags":[]},{"title":"数据结构的副本","date":"2021-01-23T07:32:01.636Z","path":"2021/01/23/数据结构的副本/","text":"数据结构跳跃表 参考跳表是在有序列表的基础上,为了提高链表的查询速度改造而来的,查询,插入和删除操作 都可以达到O(logn)级复杂度. 在一个跳表中包含索引层和基础链表层. 每个索引节点包含层级,向右兄弟节点和向下查询下级索引节点或者基础信息节点 层级是通过模拟连续抛硬币获得第一次硬币向上所需要的抛的次数来决定的.那么新节点在 第n层的概率为:$$P(n)=\\frac{1}{2^n}$$如果基础链表元素为m个,则每个索引层的节点数量大概为:$$ P(n)=\\frac{m}{2^n}$$为什么Redis选择使用跳表而不是红黑树来实现有序集合？ 首先，我们来分析下Redis的有序集合支持的操作： 1）插入元素 2）删除元素 3）查找元素 4）有序输出所有元素 5）查找区间内所有元素 其中，前4项红黑树都可以完成，且时间复杂度与跳表一致。 但是，最后一项，红黑树的效率就没有跳表高了。 在跳表中，要查找区间的元素，我们只要定位到两个区间端点在最低层级的位置，然后按顺序遍历元素就可以了，非常高效。 而红黑树只能定位到端点后，再从首位置开始每次都要查找后继节点，相对来说是比较耗时的(中序遍历)。 此外，跳表实现起来很容易且易读，红黑树实现起来相对困难，所以Redis选择使用跳表来实现有序集合。 类比 跳跃表类似于 B+树 红黑树类似于B树, 采用B+树进行范围查询时比较快","slug":"数据结构的副本","updated":"2021-01-24T06:17:52.044Z","comments":true,"categories":[],"tags":[]},{"title":"Voliate的副本","date":"2021-01-22T13:17:31.750Z","path":"2021/01/22/Voliate的副本/","text":"Voliatevolatile是Java提供的一种轻量级的同步机制。Java 语言包含两种内在的同步机制：同步块（或方法）和 volatile 变量，相比于synchronized（synchronized通常称为重量级锁），volatile更轻量级，因为它不会引起线程上下文的切换和调度。 volatile变量的特性保证可见性，不保证原子性a.当写一个volatile变量时，JMM会把该线程本地内存中的变量强制刷新到主内存中去； b.这个写会操作会导致其他线程中的缓存无效。 c.在读取volatile变量时,会主内存中的数据刷新到本地内存变量中去. d.不加锁的情况下,voliate变量参与的操作整体不能保证是原子性的. 禁止指令重排重排序是指编译器和处理器为了优化程序性能而对指令序列进行排序的一种手段。重排序需要遵守一定规则： a.重排序操作不会对存在数据依赖关系的操作进行重排序。 b.重排序是为了优化性能，但是不管怎么重排序，单线程下程序的执行结果不能被改变. 若用volatile修饰共享变量，在编译时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序,volatile禁止指令重排序也有一些规则： a.当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； b.在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 从缓存一致性的角度理解volatile 参考 在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（MainMemory）。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致，举例说明变量在多个CPU之间的共享。如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly及Dragon Protocol等。 在JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。 简单的描述缓存一致性问题：对于某个共享变量，每个操作单元都缓存一个该变量的副本。当一个操作单元更新其副本时，其他的操作单元可能没有及时发现，进而产生缓存一致性问题。 在JMM众多的访问规则中，关于volatile有这样一条规则：（引用自Happens-before Order） A write to a volatile field happens-before every subsequent read of that field. 对一个volatile变量的写操作happen-before对这个变量之后的每一个读操作 happen-before的含义如下：（引用自Happens-before Order） If one action happens-before another, then the first is visible to and ordered before the second. 如果指令甲happens-before指令乙，那么指令甲必须排序在指令乙之前，并且指令甲的执行结果对指令乙可见。 从规则的定义可知，如果多个线程同时操作volatile变量，那么对该变量的写操作必须在读操作之前执行(禁止重排序)，并且写操作的结果对读操作可见（强缓存一致性）。 Volatile如何保证可见性,禁止指令重排参考 volatile是通过编译器在生成字节码时，在指令序列中添加“内存屏障”来禁止指令重排序的 硬件层面的“内存屏障”： sfence：即写屏障(Store Barrier)，在写指令之后插入写屏障，能让写入缓存的最新数据写回到主内存，以保证写入的数据立刻对其他线程可见 lfence：即读屏障(Load Barrier)，在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据，以保证读取的是最新的数据。 mfence：即全能屏障(modify/mix Barrier )，兼具sfence和lfence的功能 lock 前缀：lock不是内存屏障，而是一种锁。执行时会锁住内存子系统来确保执行顺序，甚至跨多个CPU。 JMM层面的“内存屏障”： LoadLoad屏障： 对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad屏障： 对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。 JVM的实现会在volatile读写前后均加上内存屏障，在一定程度上保证有序性。如下所示： LoadLoadBarriervolatile 读操作LoadStoreBarrier StoreStoreBarriervolatile 写操作StoreLoadBarrier","slug":"Voliate的副本","updated":"2021-01-23T08:22:56.400Z","comments":true,"categories":[],"tags":[]},{"title":"缓存的副本","date":"2021-01-22T13:11:56.305Z","path":"2021/01/22/缓存的副本/","text":"如何保证 Redis 缓存与数据库双写一致性参考下面4种方式: 先更新数据库，后更新缓存 先更新缓存，后更新数据库 先删除缓存，后更新数据库 先更新数据库，后删除缓存 方式1,2基本不使用,因为有的业务需求缓存中存在的值并不是直接从数据库中查出来的，有的是需要经过一系列计算来的缓存值，那么这时候后你要更新缓存的话其实代价是很高的。如果此时有大量的对数据库进行写数据的请求，但是读请求并不多，那么此时如果每次写请求都更新一下缓存，那么性能损耗是非常大的。 方式3 考虑数据库的主从数据同步延迟,更新数据库后不能直接删除缓存,可以通过EPX监听从库数据变更消息来删除redis中的数据.或者更新redis数据时直接查询主库. 方式4![image-20210117165532711](/Users/limengli/Library/Application Support/typora-user-images/image-20210117165532711.png) 缓存雪崩缓存雪崩表示在某一时间段，缓存集中失效，导致请求全部走数据库，有可能搞垮数据库，使整个服务瘫痪。 使缓存集中失效的原因： 1、redis服务器挂掉了。 2、对缓存数据设置了相同的过期时间，导致某时间段内缓存集中失效。 如何解决缓存集中失效： 1、针对原因1，可以实现redis的高可用，Redis Cluster 或者 Redis Sentinel(哨兵) 等方案。 2、针对原因2，设置缓存过期时间时加上一个随机值，避免缓存在同一时间过期。 或者使用定时任务定时更新缓存数据. 3、使用双缓存策略，设置两个缓存，原始缓存和备用缓存，原始缓存失效时，访问备用缓存，备用缓存失效时间设置长点。 缓存穿透缓存穿透表示查询一个一定不存在的数据，由于没有获取到缓存，所以没写入缓存，导致这个不存在的数据每次都需要去数据库查询，失去了缓存的意义。 请求的数据大量的没有获取到缓存，导致走数据库，有可能搞垮数据库，使整个服务瘫痪。 解决方案： 1、对于像ID为负数的非法请求直接过滤掉，采用布隆过滤器(Bloom Filter)。 2、针对在数据库中找不到记录的，我们仍然将该空数据存入缓存中，当然一般会设置一个较短的过期时间, 这种方式占用存储空间,存储一些无用的数据. 缓存击穿缓存击穿表示某个key的缓存非常热门，有很高的并发一直在访问，如果该缓存失效，那同时会走数据库，压垮数据库。 缓存击穿与缓存雪崩的区别是这里针对的是某一热门key缓存，而雪崩针对的是大量缓存的集中失效。 解决方案： 1、让该热门key的缓存永不过期。 2、使用互斥锁，通过redis的setnx实现互斥锁, 保证只有一个线程能查询并更新缓存数据.","slug":"缓存的副本","updated":"2021-01-22T13:13:37.429Z","comments":true,"categories":[],"tags":[]},{"title":"事务的ACID的副本","date":"2021-01-18T14:13:29.066Z","path":"2021/01/18/事务的ACID的副本/","text":"事务的ACID原子性: 是指事物是一个不可分割的操作,最小的执行单元,事务中的操作要么全部执行,如果其中一个操作失败, 需要回滚到实物执行前的状态. 回滚操作依赖于 undo log日志, 在对数据库进行变更操作前,会把操作记录到 undo log中, 如果事务执行失败就会,根据 undo log中记录的操作,执行相反的操作来恢复数据. 持久性: 是指事物一旦提交,对数据库的修改是持久性的,将想要的数据持久化到磁盘中. mysql中的数据是存在于磁盘中的,读取磁盘中的数据需要执行io操作,为了减少IO操作,mysql数据库提供了缓存buffer,包含了磁盘部分数据页的映射,作为访问数据库的映射,当数据读取数据时,会先从buffer中读取,在buffer中查不到时,才从磁盘中查找,并且将查到的数据再放到buffer中. 在向数据库写入数据时也会想buffer中写,定期刷新缓存. 这里增加数据丢失的风险,在buffer中的数据没有刷到磁盘中,数据库宕机了,就会造成数据丢失. 为了解决这个问题,mysql引入了redo log ,在更新数据库时,处理将数据写入buffer中还需要将操作记录到redo log 中. 向buffer中写入数据属于随机io,修改数据是随机的, 向redo log 写入操作是在文件尾部追加,是顺序io 操作比较快. buffer是以数据页为单位(默认16k),数据页中一个小小的修改,就需要将整个数据页写入,redo log 只需要写入变更的部分,无效IO大大减小. redo log 会比 buffer 同步磁盘的速度快很多.redo log 信息会先放到 redo log 缓冲区, 如果这时候宕机了,由于事务还没有提交, 可以通过redo log 进行回滚. redo log 有3种持久化机制: 当事务提交时,不将缓冲区写入磁盘,而是等待主线程每秒刷新. 当事务提交时将缓冲区同步写入磁盘,保证一定写入成功. 当事务提交时将缓冲区异步写入磁盘,不保证一定写入成功. 隔离性写-写操作: 使用锁进行隔离 当多个事务同时对相同的记录记性更新操作,事务需要首先获取锁才能进行操作. 写-读操作: MVCC 参考 参考","slug":"事务的ACID的副本","updated":"2021-01-24T07:01:55.751Z","comments":true,"categories":[],"tags":[]},{"title":"BloomFilter的副本","date":"2021-01-18T13:29:29.763Z","path":"2021/01/18/BloomFilter的副本/","text":"Bloom Filter 参考 Bloom Filter Calculator Bloom Filters 哈希函数哈希函数的概念是：将任意大小的输入数据转换成特定大小的输出数据的函数，转换后的数据称为哈希值或哈希编码，也叫散列值。 如果两个散列值是不相同的（根据同一函数），那么这两个散列值的原始输入也是不相同的。这个特性是散列函数具有确定性的结果，具有这种性质的散列函数称为单向散列函数。 散列函数的输入和输出不是唯一对应关系的，如果两个散列值相同，两个输入值很可能是相同的，但也可能不同，这种情况称为“散列碰撞（collision）”。 数据结构BloomFilter 是由一个固定大小的二进制向量或者位图（bitmap）和一系列映射函数组成的。在初始状态时，对于长度为 m 的位数组，它的所有位都被置为0，如下图所示: 当有变量被加入集合时，通过 K 个映射函数将这个变量映射成位图中的 K 个点，把它们置为 1（假定有两个变量都通过 3 个映射函数）。 查询某个变量的时候我们只要看看这些点是不是都是 1 就可以大概率知道集合中有没有它了 如果这些点有任何一个 0，则被查询变量一定不在； 如果都是 1，则被查询变量很可能存在 误判率布隆过滤器的误判是指多个输入经过哈希之后在相同的bit位置1了，这样就无法判断究竟是哪个输入产生的，因此误判的根源在于相同的 bit 位被多次映射且置 1。 这种情况也造成了布隆过滤器的删除问题，因为布隆过滤器的每一个 bit 并不是独占的，很有可能多个元素共享了某一位。如果我们直接删除这一位的话，会影响其他的元素。(比如上图中的第 3 位) 关键参数位数组长度: m 哈希函数个数: k 已添加元素数量: n 误判率( false positive probability ) : fpp$$m=-\\frac{n\\ln{P_fp}}{({\\ln2})^2}$$ 特性 一个元素如果判断结果为存在的时候元素不一定存在，但是判断结果为不存在的时候则一定不存在。 布隆过滤器可以添加元素，但是不能删除元素。因为删掉元素会导致误判率增加。 优点相比于其它的数据结构，布隆过滤器在空间和时间方面都有巨大的优势。布隆过滤器存储空间和插入/查询时间都是常数 ，另外，散列函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势 缺点随着存入的元素数量增加，误算率随之增加。一般情况下不能从布隆过滤器中删除元素. 实现Guava 中的 BloomFilter1234&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;&#x2F;groupId&gt; &lt;artifactId&gt;guava&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; Redission中的 RedissonBloomFilter应用设置参数白名单,预防缓存击穿","slug":"BloomFilter的副本","updated":"2021-01-24T06:10:44.579Z","comments":true,"categories":[],"tags":[]},{"title":"分布式锁的副本","date":"2021-01-17T07:12:04.519Z","path":"2021/01/17/分布式锁的副本/","text":"基于Redis的分布式锁 参考1 参考2 方式1 适用于单节点​ 当前多个线程同时竞争某个资源时,首先需要获取资源对应的锁,锁相当于某一特定资源的使用权限,怎么定义一个线程成功获取到锁呢? 在redis中可以通过某个线程是否首先成功创建某一key来模拟此线程是否成功锁定资源,在redis操作中可以通过Set 命令来实现. 锁的释放通过命令DEL删除key来实现. 12SET key value [EX seconds] [PX milliseconds] NX DEL key; 为了避免redis数据库使用内存溢出, key必须设置过期时间 2.6.12 版本后,set 命令支持通过原子的方式同时设置键,值和过期时间 由于key设置了过期时间,在线程处理时间超过过期时间时,锁会被删除,或者被其他线程重新获取,当前线程再释放锁时可能会把其他线程持有的锁删除.为了避免这种情况,通过将value设置一个随机值,在释放锁的时候校验value的值来确定是否应该执行释放锁的操作. ​ 此方式存在一些问题: 不能保证一个锁只被一个线程持有, 在 线程执行时间超过key的过期时间时,key会被删除或者被其他线程抢占. 不支持锁的重入 方式2:RedissionLock 适用于单节点在RedissionLock实现中通过Lua脚本来保证redis操作的原子性.并且采用Hash数据结构来构建锁,其中用包含线程id的字符串作为hash中key, 用线程的重入状态作为value,相同线程执行lock操作时value加一,执行unlock时减一.加锁操作如下,其中 KEYS[1]是锁名称, ARGV[1]是过期时间,ARGV[2]是包含线程id字符串. 1234567891011if (redis.call('exists', KEYS[1]) == 0) then ## 如果锁不存在就进行加锁 redis.call('hset', KEYS[1], ARGV[2], 1); ## 创建 hash锁 并设置过期时间 redis.call('pexpire', KEYS[1], ARGV[1]); return nil;end;if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then ## 当前线程持有锁并且重入 value +1 并更新过期时间 redis.call('hincrby', KEYS[1], ARGV[2], 1); redis.call('pexpire', KEYS[1], ARGV[1]); return nil; \" + end; return redis.call('pttl', KEYS[1]); ## 查寻锁的剩余过期时间并返回 解锁锁操作如下,其中 KEYS[1]是锁名称,KEYS[2]是用于监控锁状态的订阅通道名, ARGV[1]是解锁消息,ARGV[2]是过期时间.ARGV[3]是包含线程id字符串. 1234567891011121314151617if (redis.call('exists', KEYS[1]) == 0) then ## 如果锁不存在 就发布解锁信息 redis.call('publish', KEYS[2], ARGV[1]); return 1; end;if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then ## 如果当前线程没有持有锁,直接返回 return nil; end; local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); ##有持有锁的线程计数减一if (counter &gt; 0) then ## 计数器大于0时,更新过期时间 redis.call('pexpire', KEYS[1], ARGV[2]); return 0;else ## 计数器不大于0时,删除锁,发布解锁消息 redis.call('del', KEYS[1]); redis.call('publish', KEYS[2], ARGV[1]); return 1;end; return nil; 为了防止程序执行时间大于锁的过期时间,导致锁被删除, RedissionLock 采用Watch Dog的 方式为每个锁设置 一个定时任务,在锁没有被释放前,定时更新锁的过期时间, RedissionLock的默认过期时间为30s,定时任务每个10秒更新锁的过期时间. 在主从模式的redis服务获取锁后,master宕机,并且锁数据没有同步到slaver上,在master 重启后,会被其他线程获取,导致一个锁被两个线程获取 方式3 适用于集群 参考:RedLock为了更好的理解我们想要改进的方面，我们先分析一下当前大多数基于Redis的分布式锁现状和实现方法. 实现Redis分布式锁的最简单的方法就是在Redis中创建一个key，这个key有一个失效时间（TTL)，以保证锁最终会被自动释放掉（这个对应特性2）。当客户端释放资源(解锁）的时候，会删除掉这个key。 从表面上看，似乎效果还不错，但是这里有一个问题：这个架构中存在一个严重的单点失败问题。如果Redis挂了怎么办？你可能会说，可以通过增加一个slave节点解决这个问题。但这通常是行不通的。这样做，我们不能实现资源的独享,因为Redis的主从同步通常是异步的。 在这种场景（主从结构）中存在明显的竞态: 客户端A从master获取到锁 在master将锁同步到slave之前，master宕掉了。 slave节点被晋级为master节点 客户端B取得了同一个资源被客户端A已经获取到的另外一个锁。 在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。 我们确保将在每（N)个实例上之前的方法获取和释放锁。 为了取到锁，客户端应该执行以下操作: 获取当前Unix时间，以毫秒为单位。 依次尝试从N个实例，使用相同的key和随机值获取锁。在步骤2，当向Redis设置锁时,客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试另外一个Redis实例。 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间。 如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功)。 还是不能解决故障重启后带来的锁的安全性的问题。你想一下下面这个场景： 我们一共有 A、B、C 这三个节点。 1.客户端 1 在 A，B 上加锁成功。C 上加锁失败。 2.这时节点 B 崩溃重启了，但是由于持久化策略导致客户端 1 在 B 上的锁没有持久化下来。 客户端 2 发起申请同一把锁的操作，在 B，C 上加锁成功。 3.这个时候就又出现同一把锁，同时被客户端 1 和客户端 2 所持有了。 其他问题线程长时间阻塞并且持有的锁过期,导致锁被占用如下图所示: 1.客户端 1 先去申请锁，并且成功获取到锁。之后客户端进行了长时间的 GC 导致了 STW 的情况。 2.在 STW 期间，客户端 1 获取的锁的超时时间到了，锁也就失效了。 3.由于客户端 1 的锁已经过期失效了，所以客户端 2 去申请锁就可以成功获得锁。 4.客户端 2 开始写文件，并完成文件的写入。 5.客户端 1 从 STW 中恢复过来，他并不知道自己的锁过期了，还是会继续执行文件写入操作，导致客户端 2 写入的文件被破坏。而且可以看到，它没有满足锁在任意时刻只有一个客户端持有的原则，即没有满足互斥性。 严重依赖系统时钟,在系统始终跳跃时造成锁失效,导致一个锁被不同线程占用. 1.客户端 1 从 Redis 节点 A, B, C 成功获取了锁。由于网络问题，无法访问 D 和 E。 2.节点 C 上的时钟发生了向前跳跃，导致它上面维护的锁过期了。 3.客户端 2 从 Redis 节点 C, D, E 成功获取了同一个资源的锁。由于网络问题，无法访问 A 和 B。 现在，客户端 1 和客户端 2 都认为自己持有了锁。 这样的场景是可能出现的，因为 Redlock 严重依赖系统时钟，所以一旦系统的时间变得不准确了，那么该算法的安全性也就得不到保障了。 Zookeeper12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt; 123456RetryPolicy retryPolicy=new ExponentialBackoffRetry(10000,3);CuratorFramework newClient = CuratorFrameworkFactory.newClient(\"XXX\", 30, 10, retryPolicy);InterProcessMutex interProcessMutex=new InterProcessMutex(newClient,\"/test/lock\");interProcessMutex.acquire();TimeUnit.SECONDS.sleep(60);interProcessMutex.release();","slug":"分布式锁的副本","updated":"2021-02-01T09:34:13.937Z","comments":true,"categories":[],"tags":[]},{"title":"画图工具","date":"2020-09-05T02:29:46.264Z","path":"2020/09/05/画图工具/","text":"idea中安装plantuml如果出现下面问题,还需要安装Graphviz brew install Graphviz 前提是安装过brew，如果没有安装 参考brew安装plantuml官网plantuml插件安装brew数据源替换","slug":"画图工具","updated":"2020-09-05T02:29:46.264Z","comments":true,"categories":[],"tags":[]},{"title":"获取内存快照","date":"2020-09-05T02:29:46.257Z","path":"2020/09/05/获取内存快照/","text":"获取DUMP快照 参考 启动参数配置OOM时触发打印堆快照1.tomcat启动方式添加参数123(添加环境变量) export JAVA_OPTS= -XX:+HeapDumpOnOutOfMemoryError (表明进行统计相关heapDump文件再OOM的时候)-XX:HeapDumpPath=/export/Domains/rcsv-fm.wd.local/server1/logs/gc.hprof（表明会导出生产的HeapDump文件的路径） 2.jvm 命令参数123456 (添加环境变量) Java -jar -XX:+HeapDumpOnOutOfMemoryError (表明进行统计相关heapDump文件再OOM的时候) -XX:HeapDumpPath=/export/Domains/rcsv-fm.wd.local/server1/logs/gc.hprof（表明会导出生产的HeapDump文件的路径） （1）-XX:+HeapDumpOnOutOfMemoryError参数表示当JVM发生OOM时，自动生成DUMP文件。（2）-XX:HeapDumpPath=$&#123;目录&#125;参数表示生成DUMP文件的路径，也可以指定文件名称，例如：-XX:HeapDumpPath=$&#123;目录&#125;/java_heapdump.hprof。如果不指定文件名，默认为：java_&lt;pid&gt;_&lt;date&gt;_&lt;time&gt;_heapDump.hprof。 启动参数配置OOM时触发打印堆快照 启动参数配置OOM时触发打印堆快照jmap -dump:format=b,file=xxx.hprof pid jmap -dump:format=b,file=/path/heap.bin 进程ID 如果只dump heap中的存活对象，则加上选项-live。 kill -3 or -9 都不会打堆快照，kill jvm来不及做任何事情就被干掉了，-3会打印thread dump 但是不是heap dump。 ps -ef|grep tomcat #获取tomcat的pid/jps -lv -XX:+PrintGCDetails -Xloggc:/opt/logs/gc.log -verbose:gc jmap -histo:live pid&gt;a.log","slug":"获取内存快照","updated":"2020-09-05T02:29:46.257Z","comments":true,"categories":[],"tags":[]},{"title":"分析内存快照","date":"2020-09-05T02:29:46.246Z","path":"2020/09/05/分析内存快照/","text":"Eclipse Memory Analyzer 1.安装下载地址修改初始化参数 MemoryAnalyzer.ini12345678-startup../Eclipse/plugins/org.eclipse.equinox.launcher_1.5.0.v20180512-1130.jar--launcher.library../Eclipse/plugins/org.eclipse.equinox.launcher.cocoa.macosx.x86_64_1.1.700.v20180518-1200-vmargs-Xmx4024m -Dorg.eclipse.swt.internal.carbon.smallFonts-XstartOnFirstThread 2.分析","slug":"分析内存快照","updated":"2020-09-05T02:29:46.246Z","comments":true,"categories":[],"tags":[]},{"title":"SpringBoot-logback","date":"2020-09-05T02:29:46.234Z","path":"2020/09/05/SpringBoot-logback/","text":"参考1参考2参考3 1.依赖实际开发中我们不需要直接添加该依赖，你会发现spring-boot-starter其中包含了 spring-boot-starter-logging，该依赖内容就是 Spring Boot 默认的日志框架 logback。 2.参数配置123456789101112131415logging.file=指定日志文件的位置(只支持默认的Logback设置。)logging.path=指定日志文件存放的目录，自动在该目录下创建spring.log日志文件(只支持默认的Logback设置。)##那些包使用怎样的日志级别 logging.level.包名，指定某个包下日志的级别,会覆盖logback配置文件中设置的日志级别logging.level.root=warnlogging.level.com.springboot.controllers=infologging.config=指定logback的配置文件的位置，默认在resources目录下的logback-spring.xmllogging.exception-conversion-word=当日志出现异常时会用到这个转换词。logging.file.max-history= 日志保存时间(只支持默认的Logback设置。)logging.file.max-size= 日志文件最大尺寸(只支持默认的Logback设置。)logging.pattern.console=用在控制台中的日志模式(stdout)。(只支持默认的Logback设置。)logging.pattern.dateformat=日志中日期模式(只支持默认的Logback设置。)logging.pattern.file=用在文件中的日志模式 (如果启用LOG_FILE)。(只支持默认的Logback设置。)logging.pattern.level=这种模式用来实施日志级别(默认%5p)。 (只支持默认的Logback设置。)logging.register-shutdown-hook= 3.logback配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!--scan=true 自动重新加载 --&gt;&lt;configuration scan=\"true\" scanPeriod=\"60 seconds\" debug=\"false\"&gt;&lt;contextName&gt;logback-demo&lt;/contextName&gt;&lt;timestamp key=\"bySecond\" datePattern=\"yyyyMMdd\"&gt;&lt;/timestamp&gt;&lt;!--输出到控制台 ConsoleAppender--&gt;&lt;appender name=\"consoleLog\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!--展示格式 layout--&gt; &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"&gt; &lt;pattern&gt; %d [%thread] %-5level %logger&#123;50&#125; %msg%n&lt;/pattern&gt; &lt;/layout&gt;&lt;/appender&gt;&lt;!--将日志信息输出到外部固定的文件中--&gt;&lt;appender name =\"LogFile\" class=\"ch.qos.logback.core.FileAppender\"&gt; &lt;file&gt;F:/testFile$&#123;bySecond&#125;.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;encoder&gt; &lt;pattern&gt;%d [%thread] %-5level %logger&#123;50&#125; %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt;&lt;appender name=\"RollingFileByTime\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;logFile.log&lt;/file&gt; &lt;!--基于时间的滚动策略--&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;logFile.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d [%thread] %-5level %logger&#123;50&#125; %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt;&lt;appender name=\"RollingFileByTimeAndSize\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;F:/logFile.log&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;logFile.%i.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;1MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d [%thread] %-5level %logger&#123;50&#125; %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt;&lt;!--指定最基础的日志输出级别--&gt;&lt;root level=\"info\"&gt; &lt;!--appender将会添加到这个loger--&gt; &lt;appender-ref ref=\"consoleLog\"/&gt;&lt;/root&gt;&lt;!--指定某包下的日志级别以及输出方式 additivity决定是否将日志信息向上级传递--&gt;&lt;!--logger用于指定摸个包下的日志处理方式--&gt;&lt;logger name=\"com.springboot.controllers\" level=\"info\" additivity=\"false\"&gt; &lt;appender-ref ref=\"LogFile\"/&gt;&lt;/logger&gt;&lt;/configuration&gt;","slug":"SpringBoot-logback","updated":"2020-09-05T02:29:46.235Z","comments":true,"categories":[],"tags":[]},{"title":"JVM","date":"2020-09-05T02:29:46.216Z","path":"2020/09/05/JVM/","text":"1.Java各个版本官方文档2.Java命令官方文档3.虚拟机参考文档4.虚拟机垃圾收调优 1. 启动服务 2.访问服务","slug":"JVM","updated":"2020-09-05T02:29:46.216Z","comments":true,"categories":[],"tags":[]},{"title":"Python-SimpleHttpServer","date":"2020-09-05T02:29:46.202Z","path":"2020/09/05/Python-SimpleHttpServer/","text":"如何下载远程服务器上的文件？如果远程服务安装了python， 我们可以通过启动一个python自带的SimpleHTTPServer来实现。 1. 启动服务在安装了Python的服务器上,可以使用python -m SimpleHTTPServer [port] 快速搭建一个http服务.在启动时，首先定位到需要访问的文件所在的目录，然后在该目录下启动，就可以访问该目录下有权限的资源了。 2.访问服务使用http://[ip]:[port]来进行访问","slug":"Python-SimpleHttpServer","updated":"2020-09-05T02:29:46.202Z","comments":true,"categories":[],"tags":[]},{"title":"SpringBoot-Actuator-Prometheus","date":"2020-09-05T02:28:18.084Z","path":"2020/09/05/SpringBoot-Actuator-Prometheus/","text":"SpringbootActuator 提供了用于生产环境以http端点以及JMX方式监控应用的功能 1. 依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;version&gt;2.3.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 2. Endpoints Endpoint: 监测点, 通过监测点获取监测数据。 2.1 内置EndPoints ID 作用 env 查询ConfigurableEnvironment中的属性信息 health 查询应用的健康状况 loggers 查询和修改应用日志配置 shutdown 关闭应用 threaddump 执行线程转储动作 heapdump 下载线程转储文件 prometheus 以能够被Prometheus服务器识别的格式提供指标数据 ………. 还有其他EndPoint参见官网 2.2 对外暴露EndPoint监测点会包含应用的敏感信息，可以通过配置来选择暴露合适的监测点 1234567891011121314# JMX 方式management.endpoints.jmx.exposure.exclude=management.endpoints.jmx.exposure.include= \"*\"# http 方式management.endpoints.web.exposure.exclude=management.endpoints.web.exposure.include=info, health``` ##### 2.3 开启EndPoint通过配置 management.endpoint.&lt;id&gt;.enabled属性来开启EndPoint``` bash# 所有内置EndPoint默认关闭management.endpoints.enabled-by-default=false#开启prometheus监测点management.endpoint.prometheus.enabled=true","slug":"SpringBoot-Actuator-Prometheus","updated":"2020-09-05T02:28:18.085Z","comments":true,"categories":[],"tags":[]},{"title":"Hello World","date":"2019-11-02T11:23:28.823Z","path":"2019/11/02/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","slug":"hello-world","updated":"2019-11-02T11:23:28.823Z","comments":true,"categories":[],"tags":[]}]